{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 8. Снижение размерности данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Обучить любую модель классификации на датасете IRIS до применения PCA и после него. Сравнить качество классификации по отложенной выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Классификация до применния PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = datasets.load_iris(return_X_y=True)\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features = 20, n_informative=5, n_classes=3, n_clusters_per_class=1, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5872641509433963"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Классификация после применния PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    X_ = X.astype(float)\n",
    "    rows, cols = X_.shape\n",
    "    # центрирование - вычитание из каждого значения среднего по строке\n",
    "    means = X_.mean(0)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            X_[i, j] -= means[j]\n",
    "    # деление каждого значения на стандартное отклонение\n",
    "    std = np.std(X_, axis=0)\n",
    "    for i in range(cols):\n",
    "        for j in range(rows):\n",
    "            X_[j][i] /= std[i]\n",
    "            \n",
    "    return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X_, min_var=5.0):\n",
    "    X = scale(X_)\n",
    "    # Найдем собственные векторы и собственные значения\n",
    "    covariance_matrix = X.T.dot(X)\n",
    "    eig_values, eig_vectors = np.linalg.eig(covariance_matrix)\n",
    "    # сформируем список кортежей (собственное значение, собственный вектор)\n",
    "    eig_pairs = [(np.abs(eig_values[i]), eig_vectors[:, i]) for i in range(len(eig_values))]\n",
    "    # и отсортируем список по убыванию собственных значений\n",
    "    eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    eig_sum = sum(eig_values)\n",
    "    var_exp = [(i / eig_sum) * 100 for i in sorted(eig_values, reverse=True)]\n",
    "    print(f'Доля дисперсии, описываемая каждой из компонент \\n{var_exp}')\n",
    "    # Сформируем вектор весов из собственных векторов, соответствующих главным компонентам\n",
    "    n = len(eig_values)\n",
    "    vectors = list()\n",
    "    for i, var in enumerate(var_exp):\n",
    "        if (var > min_var):\n",
    "            vectors.append(eig_pairs[i][1].reshape(n,1))\n",
    "    W = np.hstack(tuple(vectors))\n",
    "    \n",
    "    return X.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля дисперсии, описываемая каждой из компонент \n",
      "[13.812199086013925, 12.199143237119674, 7.700224491872194, 7.108175376457125, 6.472666654406621, 6.353668923409872, 5.87303159177406, 5.608021539663833, 5.464156398782314, 4.525878490925064, 4.39588561333654, 4.122037807971374, 3.793479063389583, 3.2733423937898958, 3.043194075820405, 2.78008737489931, 2.024662420654246, 1.450145459713974, 5.016100672588775e-16, -1.5737589187121325e-15]\n"
     ]
    }
   ],
   "source": [
    "Z = pca(X, min_var=3.0)\n",
    "# print(f'W \\n{W}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(Z, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051886792452831"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_pca, y_pred_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** в данном случае при малом количестве объектов и пропорционально небольшом количестве информативных признаков метод главных компонент улучшил качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции numpy.linalg.svd()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_svd(X, min_vector=5.0):\n",
    "    U, s, vh = np.linalg.svd(X)\n",
    "\n",
    "    vectors = list()\n",
    "    for i, eig_vector in enumerate(s):\n",
    "        if (eig_vector > min_vector):\n",
    "            vectors.append(eig_vector)\n",
    "    \n",
    "    n = len(vectors)\n",
    "   \n",
    "    Z = np.dot(U[:, :n], np.dot(np.diag(s[:n]), vh[:n, :]))\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_svd = pca_svd(X, min_vector=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_svd, X_test_pca_svd, y_train_pca_svd, y_test_pca_svd = train_test_split(Z, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_pca_svd, y_train_pca_svd)\n",
    "y_pred_pca_svd = model.predict(X_test_pca_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051886792452831"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_pca_svd, y_pred_pca_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** результат совпадает с предыдущей реализацией, значит функция написана верно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
